### FUNCTION DEFINITIONS
# Inverse of CLR transformation
## Input: z = grid of point defining the abscissa
##        z_step = step of the grid of the abscissa
##        clr = grid evaluation of the clr transformed density
## Output: grid evaluation of the density
clr2density <- function(z, z_step, clr){
if (is.fd(clr))
return(exp(eval.fd(z, clr)) / trapzc(z_step, exp(eval.fd(z, clr))))
else
return(exp(clr) / trapzc(z_step, exp(clr)))
}
# Numerical integration via trapezoidal formula
## Input: y = grid evaluation of the function
##        z_step = step of the grid
## Output: numerical integration over the interval
trapzc <- function(step, y){
n_pts <- length(y)
res_int <- step * (0.5*y[1] + sum(y[2:(n_pts-1)]) + 0.5*y[n_pts])
return(res_int)
}
# B-spline fitting of CLR
clr2coef <- function(z, clr, n_knot, y_start, y_end, d = 2){
norder <- d + 1                 # order of splines (degree + 1)
nbasis <- n_knot + norder - 2    # g+k+1 (dimension)
# Create bspline basis
knots <- seq(y_start, y_end, length=n_knot) # knots
splajn.basis <- create.bspline.basis(range(knots), nbasis, norder, breaks = knots)
knot_vec <- c(rep(z[1], d), z, rep(z[n_knot], d))
knot_diff <- rep(0, nbasis)
for (i in 1:nbasis){
knot_diff[i] <- knot_vec[i + norder] - knot_vec[i]
}
# Create matrix
A <- eval.basis(z, splajn.basis)
b <- clr
Dmat <- t(A) %*% A
dvec <- t(b) %*% A
bvec <- c(0)
Amat <- matrix(c(knot_diff), nbasis, 1)
x_sol <- solve.QP(Dmat, dvec, Amat, bvec=bvec, meq = 1)
return(x_sol$solution)
}
# B-spline coef to density
coef2density <- function(z, bspline.basis, x){
beta.fd <- fd(x, bspline.basis)
beta.l <- eval.fd(z, beta.fd)
res <- clr2density(z, z[2]-z[1], beta.l)
return(res)
}
# density to quantile
density2quantile <- function(z, x, q_levs){
## Input: z = equally-spaced grid of point defining the abscissa
z_step <- z[2] - z[1]
cdf <- cumsum(x) * z_step
res <- approx(cdf, z, xout = q_levs)
return(res$y)
}
# density to cdf
density2cdf <- function(z, x, y){
## Input: z = equally-spaced grid of point defining the abscissa
##        x = density values
##        y = grid of output points
z_step <- z[2] - z[1]
cdf <- cumsum(x) * z_step
res <- approx(z, cdf, xout = y)
return(res$y)
}
# load data
X <- as.matrix(read.csv('../data/dat_X.csv'))
Y <- as.matrix(read.csv('../data/dat_Y.csv'))
loc_CV <- unlist(read.csv('../data/dat_CV.csv'))
loc_CV <- loc_CV + 1
# Optional: apply Linear Regression to remove the conditional expectation ==> functional regression for residual
Y_mean <- rowMeans(Y)
model_linear <- lm(Y_mean~X)
Y_res <- Y #- predict(model_linear, data.frame(X))
# create count matrix
## choose the start points
eps <- 1e-3
y_range <- max(Y_res) - min(Y_res)
y_start <- min(Y_res) - eps
y_end <- max(Y_res) + eps
print(c(y_start, y_end))
## choose the number of bins using Sturges rule
n_bins <- as.integer(1 + log2(dim(Y)[1] * dim(Y)[2]))
step_size <- (y_end - y_start) / n_bins
## calculate the CLR of Y
loc_breaks <- seq(y_start, y_end, length.out = n_bins + 1)
Y_count <- apply(Y_res, 1, function(x) return(hist(x, breaks = loc_breaks, plot = FALSE)$counts))
# apply CLR transformation to count matrix
## process the zero counts
s <- 1 ## Perks prior
mat_alpha <- rowSums(Y_count) - Y_count
mat_t <- mat_alpha / colSums(mat_alpha)
mat_x <- Y_count / colSums(Y_count)
mat_r <- matrix(0, nrow = nrow(Y_count), ncol = ncol(Y_count))
Y_comp <- matrix(0, nrow = nrow(Y_count), ncol = ncol(Y_count))
for (i in 1:ncol(Y_count)){
for (j in 1:nrow(Y_count)){
if (mat_x[j, i] == 0){
mat_r[j, i] <- mat_t[j, i] * s / (s + n_bins)
}
}
}
for (i in 1:ncol(Y_count)){
for (j in 1:nrow(Y_count)){
if (mat_x[j, i] > 0){
Y_comp[j, i] <- mat_x[j, i] * (1 - sum(mat_r[, i]))
}
else{
Y_comp[j, i] <- mat_r[j, i]
}
}
}
Y_dens <- Y_comp / step_size
Y_clr <- apply(Y_dens, 2, function(x) return(log(x) - mean(log(x))))
## calculate the B-spline coefficient of Y_clr
y_start <- min(Y_res) - eps + step_size / 2
y_end <- max(Y_res) + eps - step_size / 2
z <- seq(y_start, y_end, length.out = n_bins)
loc_fine = seq(y_start, y_end, length.out = 256)
## nested Cross Validation
## split the data
n_fold <- max(loc_CV)
## evaluation levels
n_levs <- 100
q_sup <- c(1:(n_levs-1)) / n_levs
q_true <-t(apply(Y_res, 1, function(x) {quantile(x, q_sup)}))
q_pred <- matrix(0, nrow = nrow(q_true), ncol = ncol(q_true))
## parameter sets
norder_list <- c(2, 3, 4)
nknot_list <- c(5, 8, 10)
loss_nest <- rep(0, n_fold)
for (id_test in 1:n_fold){
print(paste0('This is fold ', id_test, '.'))
## select the test data
X_test <- X[loc_CV == id_test, ]
Y_test <- Y[loc_CV == id_test, ]
## loop over the parameter combinations
loss_val <- matrix(0, nrow=9, ncol=3)
for (i in 1:3){
norder <- norder_list[i]
for (j in 1:3){
n_knot <- nknot_list[j]
nbasis <- n_knot + norder - 2
knots <- seq(y_start, y_end, length=n_knot) # knots
loss_val[3*i + j - 3, 1] <- norder
loss_val[3*i + j - 3, 2] <- n_knot
for (id_val in setdiff(1:n_fold, id_test)){
X_val <- X[loc_CV == id_val, ]
Y_val <- Y[loc_CV == id_val, ]
X_train <- X[(loc_CV != id_val)*(loc_CV != id_test) == 1, ]
Y_train <- Y[(loc_CV != id_val)*(loc_CV != id_test) == 1, ]
clr_coef_train <- Y_clr[, (loc_CV != id_val)*(loc_CV != id_test) == 1]
Y_coef_train <- apply(clr_coef_train, 2, function(x) return(clr2coef(z, x, n_knot, y_start, y_end, d=norder-1)))
splajn.basis <- create.bspline.basis(c(y_start, y_end), nbasis, norder, breaks = knots)
X_train_full <- as.matrix(cbind(rep(1, dim(X_train)[1]), X_train))
X_val_full <- as.matrix(cbind(rep(1, dim(X_val)[1]), X_val))
B = solve(t(X_train_full)%*%X_train_full)%*%t(X_train_full)%*%as.matrix(t(Y_coef_train))
pred_val <- X_val_full %*% B
dens_val <- t(apply(pred_val, 1, function(x) return(coef2density(loc_fine, splajn.basis, x))))
quantile_val <- t(apply(dens_val, 1, function(x) return(density2quantile(loc_fine, x, q_levs = q_sup))))
q_val <-t(apply(Y_val, 1, function(x) {quantile(x, q_sup)}))
val_loss <- mean((quantile_val - q_val)^2)
loss_val[3*i + j - 3, 3] <- loss_val[3*i + j - 3, 3] + val_loss
}
}
}
loc_best <- which.min(loss_val[, 3])
#print(loss_val[, 3])
norder_best <- norder_list[ceiling(loc_best / 3)]
nknot_best <- nknot_list[(loc_best - 1) %% 3 + 1]
nbasis_best <- nknot_best + norder_best - 2
print(c(nknot_best, norder_best))
knots_best <- seq(y_start, y_end, length=nknot_best) # knots
X_train <- X[loc_CV != id_test, ]
Y_train <- Y[loc_CV != id_test, ]
clr_coef_train <- Y_clr[, loc_CV != id_test]
Y_coef_train <- apply(clr_coef_train, 2, function(x) return(clr2coef(z, x, nknot_best, y_start, y_end, d=norder_best-1)))
splajn.basis <- create.bspline.basis(c(y_start, y_end), nbasis_best, norder_best, breaks = knots_best)
X_train_full <- as.matrix(cbind(rep(1, dim(X_train)[1]), X_train))
X_test_full <- as.matrix(cbind(rep(1, dim(X_test)[1]), X_test))
B = solve(t(X_train_full)%*%X_train_full)%*%t(X_train_full)%*%as.matrix(t(Y_coef_train))
pred_test <- X_test_full %*% B
dens_test <- t(apply(pred_test, 1, function(x) return(coef2density(loc_fine, splajn.basis, x))))
quantile_test <- t(apply(dens_test, 1, function(x) return(density2quantile(loc_fine, x, q_levs = q_sup))))
q_test <-t(apply(Y_test, 1, function(x) {quantile(x, q_sup)}))
test_loss <- mean((quantile_test - q_test)^2)
loss_nest[id_test] <- test_loss
q_pred[loc_CV == id_test, ] <- quantile_test
print(c(id_test, test_loss))
}
loss_cv <- mean((q_pred - q_true)^2)
mat_res <- t(apply(q_true, 1, function(x) x - colMeans(q_true)))
var_Y <- mean(mat_res^2)
print(paste0('Test loss: ', loss_cv))
print(paste0('Test R-squared: ', 1 - loss_cv / var_Y))
# import libraries
library(frechet)
library(dplyr)
library(ggplot2)
library(parallel)
library(cowplot)
### FUNCTION DEFINITIONS
qt2cdf <- function(q_levs, x, y){
cdf <- approx(x, q_levs, xout = y)
cdf_vec <- cdf$y
cdf_vec[y < min(x)] <- 0
cdf_vec[y > max(x)] <- 1
return(cdf_vec)
}
qt2pdf <- function(q_levs, x, y){
n_y <- length(y)
cdf <- qt2cdf(q_levs, x, y)
cdf_vec <- c(2*cdf[1] - cdf[2], cdf, 2*cdf[n_y] - cdf[n_y - 1])
loc_vec <- c(2*y[1] - y[2], y, 2*y[n_y] - y[n_y - 1])
cdf_c <- c(cdf_vec[3:(n_y + 2)], 0, 0) - cdf_vec
loc_c <- c(loc_vec[3:(n_y + 2)], 0, 0) - loc_vec
pdf_vec <- cdf_c / loc_c
return(pdf_vec[1:n_y])
}
# load data
X <- as.matrix(read.csv('../../../data/simulation/setting_4/dat_X.csv'))
# load data
X <- as.matrix(read.csv('../../../../data/simulation/setting_4/dat_X.csv'))
Y <- as.matrix(read.csv('../../../../data/simulation/setting_4/dat_Y.csv'))
loc_CV <- unlist(read.csv('../../../../data/simulation/setting_4/dat_CV.csv'))
loc_CV <- loc_CV + 1
# cross validation
## split the data
n_fold <- max(loc_CV)
n_levs <- 100
q_sup <- c(0:n_levs) / n_levs
time_start <- Sys.time()
train_loss <- rep(0, n_fold)
val_loss <- rep(0, n_fold)
Y_pred_train <- matrix(0, nrow = dim(Y)[1], (n_levs+1))
Y_pred_val <- matrix(0, nrow = dim(Y)[1], (n_levs+1))
for (id_fold in 1:n_fold){
print(paste0('This is fold ', id_fold, '.'))
X_train <- X[loc_CV != id_fold, ]
Y_train <- Y[loc_CV != id_fold, ]
X_val <- X[loc_CV == id_fold, ]
Y_val <- Y[loc_CV == id_fold, ]
res_train <- GloDenReg(xin=X_train, yin=Y_train, xout=X_train, optns = list(qSup = q_sup))
res_val <- GloDenReg(xin=X_train, yin=Y_train, xout=X_val, optns = list(qSup = q_sup))
q_out_train <-t(apply(Y_train, 1, function(x) {quantile(x, q_sup)}))
q_out_val <- t(apply(Y_val, 1, function(x) {quantile(x, q_sup)}))
Y_pred_train[loc_CV != id_fold, ] <- res_train$qout
Y_pred_val[loc_CV == id_fold, ] <- res_val$qout
train_loss[id_fold] <- mean((q_out_train[, 2:n_levs] - res_train$qout[, 2:n_levs])^2)
val_loss[id_fold] <- mean((q_out_val[, 2:n_levs] - res_val$qout[, 2:n_levs])^2)
}
print(Sys.time() - time_start)
# visualize the histogram and predicted density
y_start <- quantile(Y, 0.0005)
y_end <- quantile(Y, 0.9995)
## choose the number of bins using Sturges rule
n_bins <- 5 * as.integer(1 + log2(dim(Y)[1] * dim(Y)[2]))
## calculate the CLR of Y
loc_fine = seq(y_start, y_end, length.out = 50) # locations for evaluation and visualization
pdf_train <- apply(Y_pred_train, 1, function(x) return(qt2pdf(q_sup, x, loc_fine)))
pdf_val <- apply(Y_pred_val, 1, function(x) return(qt2pdf(q_sup, x, loc_fine)))
plots_ <- list()
for (i in 1:10){
idd <- i * 5
df_dens_val <- data.frame(x=loc_fine, y=pdf_val[ , idd])
df_dens_train <- data.frame(x=loc_fine, y=pdf_train[ , idd])
df_hist <- data.frame(x=Y[idd, ])
plots_[[i]] <- ggplot(data = df_hist, aes(x=x, ..density..)) +
geom_histogram(bins = 30, fill="lightblue", color='blue') +
geom_line(data = df_dens_train, aes(x=x,y=y),  color='red') +
geom_line(data = df_dens_val, aes(x=x,y=y),  color='orange') +
theme(legend.position = "none") + theme_bw()
}
#grid.arrange(plots_[[1]], plots_[[2]], plots_[[3]], plots_[[4]], nrow = 1)
plot_grid(plots_[[1]], plots_[[2]], plots_[[3]], plots_[[4]], plots_[[5]],
plots_[[6]], plots_[[7]], plots_[[8]], plots_[[9]], plots_[[10]],
ncol = 5, rel_widths = c(1, 1, 1, 1, 1))
# calculate R-squared
val_loss <- mean(val_loss)
train_loss <- mean(train_loss)
q_Y <- t(apply(Y, 1, function(x) {quantile(x, q_sup)}))
mat_res <- t(apply(q_Y, 1, function(x) x - colMeans(q_Y)))
var_Y <- mean(mat_res[, 2:n_levs]^2)
r_square_train <- 1 - train_loss / var_Y
r_square_val <- 1 - val_loss / var_Y
print(paste0('Output variance: ', var_Y))
print(paste0('Train loss: ', train_loss))
print(paste0('Train R-squared: ',r_square_train))
print(paste0('Test loss: ', val_loss))
print(paste0('Test R-squared: ',r_square_val))
write.csv(Y_pred_val, file = '../output/qt_Frechet.csv')
# calculate R-squared
val_loss <- mean(val_loss)
train_loss <- mean(train_loss)
q_Y <- t(apply(Y, 1, function(x) {quantile(x, q_sup)}))
mat_res <- t(apply(q_Y, 1, function(x) x - colMeans(q_Y)))
var_Y <- mean(mat_res[, 2:n_levs]^2)
r_square_train <- 1 - train_loss / var_Y
r_square_val <- 1 - val_loss / var_Y
print(paste0('Output variance: ', var_Y))
print(paste0('Train loss: ', train_loss))
print(paste0('Train R-squared: ',r_square_train))
print(paste0('Test loss: ', val_loss))
print(paste0('Test R-squared: ',r_square_val))
#write.csv(Y_pred_val, file = '../output/qt_Frechet.csv')
# import libraries
library(fda)
library(quadprog)
library(ggplot2)
library(cowplot)
library(gridExtra)
### FUNCTION DEFINITIONS
# Inverse of CLR transformation
## Input: z = grid of point defining the abscissa
##        z_step = step of the grid of the abscissa
##        clr = grid evaluation of the clr transformed density
## Output: grid evaluation of the density
clr2density <- function(z, z_step, clr){
if (is.fd(clr))
return(exp(eval.fd(z, clr)) / trapzc(z_step, exp(eval.fd(z, clr))))
else
return(exp(clr) / trapzc(z_step, exp(clr)))
}
# Numerical integration via trapezoidal formula
## Input: y = grid evaluation of the function
##        z_step = step of the grid
## Output: numerical integration over the interval
trapzc <- function(step, y){
n_pts <- length(y)
res_int <- step * (0.5*y[1] + sum(y[2:(n_pts-1)]) + 0.5*y[n_pts])
return(res_int)
}
# B-spline fitting of CLR
clr2coef <- function(z, clr, n_knot, y_start, y_end, d = 2){
norder <- d + 1                 # order of splines (degree + 1)
nbasis <- n_knot + norder - 2    # g+k+1 (dimension)
# Create bspline basis
knots <- seq(y_start, y_end, length=n_knot) # knots
splajn.basis <- create.bspline.basis(range(knots), nbasis, norder, breaks = knots)
knot_vec <- c(rep(z[1], d), z, rep(z[n_knot], d))
knot_diff <- rep(0, nbasis)
for (i in 1:nbasis){
knot_diff[i] <- knot_vec[i + norder] - knot_vec[i]
}
# Create matrix
A <- eval.basis(z, splajn.basis)
b <- clr
Dmat <- t(A) %*% A
dvec <- t(b) %*% A
bvec <- c(0)
Amat <- matrix(c(knot_diff), nbasis, 1)
x_sol <- solve.QP(Dmat, dvec, Amat, bvec=bvec, meq = 1)
return(x_sol$solution)
}
# B-spline coef to density
coef2density <- function(z, bspline.basis, x){
beta.fd <- fd(x, bspline.basis)
beta.l <- eval.fd(z, beta.fd)
res <- clr2density(z, z[2]-z[1], beta.l)
return(res)
}
# density to quantile
density2quantile <- function(z, x, q_levs){
## Input: z = equally-spaced grid of point defining the abscissa
z_step <- z[2] - z[1]
cdf <- cumsum(x) * z_step
res <- approx(cdf, z, xout = q_levs)
return(res$y)
}
# density to cdf
density2cdf <- function(z, x, y){
## Input: z = equally-spaced grid of point defining the abscissa
##        x = density values
##        y = grid of output points
z_step <- z[2] - z[1]
cdf <- cumsum(x) * z_step
res <- approx(z, cdf, xout = y)
return(res$y)
}
# load data
X <- as.matrix(read.csv('../../../../data/simulation/setting_4/dat_X.csv'))
Y <- as.matrix(read.csv('../../../../data/simulation/setting_4/dat_Y.csv'))
loc_CV <- unlist(read.csv('../../../../data/simulation/setting_4/dat_CV.csv'))
loc_CV <- loc_CV + 1
# Optional: apply Linear Regression to remove the conditional expectation ==> functional regression for residual
Y_mean <- rowMeans(Y)
model_linear <- lm(Y_mean~X)
Y_res <- Y #- predict(model_linear, data.frame(X))
# create count matrix
## choose the start points
eps <- 1e-3
y_range <- max(Y_res) - min(Y_res)
y_start <- min(Y_res) - eps
y_end <- max(Y_res) + eps
print(c(y_start, y_end))
## choose the number of bins using Sturges rule
n_bins <- as.integer(1 + log2(dim(Y)[1] * dim(Y)[2]))
step_size <- (y_end - y_start) / n_bins
## calculate the CLR of Y
loc_breaks <- seq(y_start, y_end, length.out = n_bins + 1)
Y_count <- apply(Y_res, 1, function(x) return(hist(x, breaks = loc_breaks, plot = FALSE)$counts))
# apply CLR transformation to count matrix
## process the zero counts
s <- 1 ## Perks prior
mat_alpha <- rowSums(Y_count) - Y_count
mat_t <- mat_alpha / colSums(mat_alpha)
mat_x <- Y_count / colSums(Y_count)
mat_r <- matrix(0, nrow = nrow(Y_count), ncol = ncol(Y_count))
Y_comp <- matrix(0, nrow = nrow(Y_count), ncol = ncol(Y_count))
for (i in 1:ncol(Y_count)){
for (j in 1:nrow(Y_count)){
if (mat_x[j, i] == 0){
mat_r[j, i] <- mat_t[j, i] * s / (s + n_bins)
}
}
}
for (i in 1:ncol(Y_count)){
for (j in 1:nrow(Y_count)){
if (mat_x[j, i] > 0){
Y_comp[j, i] <- mat_x[j, i] * (1 - sum(mat_r[, i]))
}
else{
Y_comp[j, i] <- mat_r[j, i]
}
}
}
Y_dens <- Y_comp / step_size
Y_clr <- apply(Y_dens, 2, function(x) return(log(x) - mean(log(x))))
## calculate the B-spline coefficient of Y_clr
y_start <- min(Y_res) - eps + step_size / 2
y_end <- max(Y_res) + eps - step_size / 2
z <- seq(y_start, y_end, length.out = n_bins)
loc_fine = seq(y_start, y_end, length.out = 256)
## nested Cross Validation
## split the data
n_fold <- max(loc_CV)
## evaluation levels
n_levs <- 100
q_sup <- c(1:(n_levs-1)) / n_levs
q_true <-t(apply(Y_res, 1, function(x) {quantile(x, q_sup)}))
q_pred <- matrix(0, nrow = nrow(q_true), ncol = ncol(q_true))
## parameter sets
norder_list <- c(2, 3, 4)
nknot_list <- c(5, 8, 10)
loss_nest <- rep(0, n_fold)
for (id_test in 1:n_fold){
print(paste0('This is fold ', id_test, '.'))
## select the test data
X_test <- X[loc_CV == id_test, ]
Y_test <- Y[loc_CV == id_test, ]
## loop over the parameter combinations
loss_val <- matrix(0, nrow=9, ncol=3)
for (i in 1:3){
norder <- norder_list[i]
for (j in 1:3){
n_knot <- nknot_list[j]
nbasis <- n_knot + norder - 2
knots <- seq(y_start, y_end, length=n_knot) # knots
loss_val[3*i + j - 3, 1] <- norder
loss_val[3*i + j - 3, 2] <- n_knot
for (id_val in setdiff(1:n_fold, id_test)){
X_val <- X[loc_CV == id_val, ]
Y_val <- Y[loc_CV == id_val, ]
X_train <- X[(loc_CV != id_val)*(loc_CV != id_test) == 1, ]
Y_train <- Y[(loc_CV != id_val)*(loc_CV != id_test) == 1, ]
clr_coef_train <- Y_clr[, (loc_CV != id_val)*(loc_CV != id_test) == 1]
Y_coef_train <- apply(clr_coef_train, 2, function(x) return(clr2coef(z, x, n_knot, y_start, y_end, d=norder-1)))
splajn.basis <- create.bspline.basis(c(y_start, y_end), nbasis, norder, breaks = knots)
X_train_full <- as.matrix(cbind(rep(1, dim(X_train)[1]), X_train))
X_val_full <- as.matrix(cbind(rep(1, dim(X_val)[1]), X_val))
B = solve(t(X_train_full)%*%X_train_full)%*%t(X_train_full)%*%as.matrix(t(Y_coef_train))
pred_val <- X_val_full %*% B
dens_val <- t(apply(pred_val, 1, function(x) return(coef2density(loc_fine, splajn.basis, x))))
quantile_val <- t(apply(dens_val, 1, function(x) return(density2quantile(loc_fine, x, q_levs = q_sup))))
q_val <-t(apply(Y_val, 1, function(x) {quantile(x, q_sup)}))
val_loss <- mean((quantile_val - q_val)^2)
loss_val[3*i + j - 3, 3] <- loss_val[3*i + j - 3, 3] + val_loss
}
}
}
loc_best <- which.min(loss_val[, 3])
#print(loss_val[, 3])
norder_best <- norder_list[ceiling(loc_best / 3)]
nknot_best <- nknot_list[(loc_best - 1) %% 3 + 1]
nbasis_best <- nknot_best + norder_best - 2
print(c(nknot_best, norder_best))
knots_best <- seq(y_start, y_end, length=nknot_best) # knots
X_train <- X[loc_CV != id_test, ]
Y_train <- Y[loc_CV != id_test, ]
clr_coef_train <- Y_clr[, loc_CV != id_test]
Y_coef_train <- apply(clr_coef_train, 2, function(x) return(clr2coef(z, x, nknot_best, y_start, y_end, d=norder_best-1)))
splajn.basis <- create.bspline.basis(c(y_start, y_end), nbasis_best, norder_best, breaks = knots_best)
X_train_full <- as.matrix(cbind(rep(1, dim(X_train)[1]), X_train))
X_test_full <- as.matrix(cbind(rep(1, dim(X_test)[1]), X_test))
B = solve(t(X_train_full)%*%X_train_full)%*%t(X_train_full)%*%as.matrix(t(Y_coef_train))
pred_test <- X_test_full %*% B
dens_test <- t(apply(pred_test, 1, function(x) return(coef2density(loc_fine, splajn.basis, x))))
quantile_test <- t(apply(dens_test, 1, function(x) return(density2quantile(loc_fine, x, q_levs = q_sup))))
q_test <-t(apply(Y_test, 1, function(x) {quantile(x, q_sup)}))
test_loss <- mean((quantile_test - q_test)^2)
loss_nest[id_test] <- test_loss
q_pred[loc_CV == id_test, ] <- quantile_test
print(c(id_test, test_loss))
}
loss_cv <- mean((q_pred - q_true)^2)
mat_res <- t(apply(q_true, 1, function(x) x - colMeans(q_true)))
var_Y <- mean(mat_res^2)
print(paste0('Test loss: ', loss_cv))
print(paste0('Test R-squared: ', 1 - loss_cv / var_Y))
